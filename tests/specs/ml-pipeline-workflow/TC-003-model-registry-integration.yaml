# Test Case 003: Model Registry Integration
# Tests MLflow integration for experiment tracking

id: TC-003
name: Model Registry Integration (MLflow)
skill: ml-pipeline-workflow
priority: P2
type: integration
estimated_duration: 20s

description: |
  Test integration with MLflow for experiment tracking and model registry.
  Validates that training metrics, hyperparameters, and model artifacts
  are properly logged.

scenario:
  use_case: Experiment Tracking and Model Versioning
  problem: Track model performance over time
  solution: MLflow integration for logging and registry

prerequisites:
  - MLflow installed (pip install mlflow)
  - MLflow server running (optional, can use local file storage)

test_steps:
  - step: 1
    action: Start MLflow experiment
    expected: Experiment created with unique ID

  - step: 2
    action: Log hyperparameters
    logged_params:
      - model: yolov8n
      - epochs: 3
      - batch_size: 2
      - img_size: 640
    expected: Parameters logged to MLflow

  - step: 3
    action: Train model with metric logging
    logged_metrics:
      - train/loss
      - val/mAP@0.5
      - val/precision
      - val/recall
    expected: Metrics logged per epoch

  - step: 4
    action: Log model artifacts
    artifacts:
      - best.pt (model weights)
      - training_plot.png
      - confusion_matrix.png
    expected: Artifacts uploaded to MLflow

  - step: 5
    action: Register model in model registry
    model_name: soccer-player-detector
    stage: Staging
    expected: Model registered with version number

  - step: 6
    action: Load model from registry
    expected: Model loads successfully and can predict

success_criteria:
  - All hyperparameters logged
  - Training metrics tracked per epoch
  - Model artifacts uploaded
  - Model registered and loadable
  - MLflow UI accessible (if server running)

optional:
  mlflow_ui: http://localhost:5000
  note: Test works with local file storage (no server needed)

author: SpecWeave Test Suite
created: 2025-10-31
