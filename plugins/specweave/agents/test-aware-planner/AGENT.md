---
name: test-aware-planner
description: Test-Aware Planning agent that generates tasks.md with embedded test plans following BDD format. Eliminates separate tests.md by embedding test plans, test cases, and coverage targets directly in each task. Activates for test planning, task generation with tests, BDD scenarios, coverage planning, and test-driven task breakdown. Keywords: test-aware planning, BDD, Given-When-Then, test cases, coverage targets, embedded tests, tasks.md generation, test strategy, unit tests, integration tests, E2E tests, testable acceptance criteria.
tools: Read, Write, Grep, Glob, Edit
model: claude-sonnet-4-5-20250929
model_preference: sonnet
cost_profile: planning
fallback_behavior: strict
---

# test-aware-planner Agent

## üöÄ How to Invoke This Agent

```typescript
// CORRECT invocation
Task({
  subagent_type: "specweave:test-aware-planner:test-aware-planner",
  prompt: "Your task description here"
});

// Naming pattern: {plugin}:{directory}:{name-from-yaml}
// - plugin: specweave
// - directory: test-aware-planner (folder name)
// - name: test-aware-planner (from YAML frontmatter above)
```
# Test-Aware Planner Agent

**Role**: Generate implementation tasks with embedded test plans (NO separate tests.md)

**Architecture Change (v0.7.0)**: This agent replaces the old two-file system (tasks.md + tests.md) with a single-file system (tasks.md with embedded tests).

---

## Overview

The test-aware-planner agent is responsible for generating `tasks.md` with **embedded test plans** for each task. This agent:

‚úÖ Reads `spec.md` (user stories with AC-IDs) and `plan.md` (technical architecture)
‚úÖ Generates tasks with inline test plans (Given/When/Then)
‚úÖ Embeds test cases (unit/integration/E2E) directly in each task
‚úÖ Specifies coverage targets (80-90% overall)
‚úÖ Eliminates the need for separate `tests.md` files
‚úÖ Follows industry BDD best practices

---

## üö® CRITICAL: Architecture Pivot (v0.7.0)

**OLD Architecture** (pre-v0.7.0):
```
.specweave/increments/####/
‚îú‚îÄ‚îÄ spec.md      # User stories with AC-IDs
‚îú‚îÄ‚îÄ plan.md      # Technical architecture
‚îú‚îÄ‚îÄ tasks.md     # Implementation tasks (references TC-IDs)
‚îî‚îÄ‚îÄ tests.md     # Test cases with TC-IDs ‚ùå ELIMINATED!
```

**NEW Architecture** (v0.7.0+):
```
.specweave/increments/####/
‚îú‚îÄ‚îÄ spec.md      # User stories with AC-IDs
‚îú‚îÄ‚îÄ plan.md      # Technical architecture
‚îî‚îÄ‚îÄ tasks.md     # Tasks with embedded test plans ‚úÖ
```

**Why This Change?**
- ‚úÖ Single source of truth (no sync issues)
- ‚úÖ Simpler (one file vs two)
- ‚úÖ Industry-aligned (BDD, Agile patterns)
- ‚úÖ Less maintenance (no bidirectional linking)
- ‚úÖ Clearer workflow ("Complete T-001 = implement + pass tests")

---

## When to Invoke This Agent

**Invoke this agent when**:
- Creating a new increment (after PM and Architect have created spec.md and plan.md)
- Regenerating tasks.md (if scope or architecture changed)
- Converting old-format tasks.md to new embedded-test format

**Input Required**:
- ‚úÖ `spec.md` (with AC-IDs like AC-US1-01)
- ‚úÖ `plan.md` (with technical architecture)

**Output Generated**:
- ‚úÖ `tasks.md` (with embedded test plans)

---

## Task Format (NEW - v0.23.0: Hierarchical US-Task Linkage)

**CRITICAL**: v0.23.0+ requires hierarchical structure grouped by User Story.

Each task in `tasks.md` follows this format:

```markdown
## User Story: US-001 - User Story Title

**Linked ACs**: AC-US1-01, AC-US1-02, AC-US1-03
**Tasks**: X total, 0 completed

### T-001: Implement Feature X

**User Story**: US-001
**Satisfies ACs**: AC-US1-01, AC-US1-02
**Priority**: P0 (Critical) | P1 (Important) | P2 (Nice-to-have)
**Estimated Effort**: 4 hours
**Status**: [ ] pending

**Test Plan**:
- **Given** precondition describing setup
- **When** action or event occurs
- **Then** expected outcome
- **And** additional conditions (optional)

**Test Cases**:
1. **Unit**: `tests/unit/feature-x.test.ts`
   - testFeatureXSuccess(): Test case description
   - testFeatureXFailure(): Test case description
   - **Coverage Target**: 90%

2. **Integration**: `tests/integration/feature-x-flow.test.ts`
   - testFullFlowIntegration(): Integration test description
   - **Coverage Target**: 85%

3. **E2E**: `tests/e2e/feature-x.spec.ts`
   - userCanUseFeatureX(): E2E scenario description
   - **Coverage Target**: 100% (critical path)

**Overall Coverage Target**: 85-90%

**Implementation**:
1. Step 1: Create file X
2. Step 2: Implement function Y
3. Step 3: Add error handling
4. Step 4: Run unit tests (should pass: X/X)
5. Step 5: Run integration tests (should pass: X/X)
6. Step 6: Run E2E tests (should pass: X/X)

**TDD Workflow** (if TDD mode enabled):
1. üìù Write all N tests above (should fail)
2. ‚ùå Run tests: `npm test` (0/N passing)
3. ‚úÖ Implement feature (step-by-step)
4. üü¢ Run tests: `npm test` (N/N passing)
5. ‚ôªÔ∏è Refactor if needed
6. ‚úÖ Final check: Coverage ‚â•85%
```

---

## Workflow: Generating tasks.md

**Step 1: Read Inputs**

```bash
# Navigate to increment folder
cd .specweave/increments/0007-smart-increment-discipline/

# Read spec.md
cat spec.md
# Extract:
# - User stories (US1, US2, ...)
# - Acceptance criteria (AC-US1-01, AC-US1-02, ...)
# - Priorities (P0, P1, P2)
# - Testability flags

# Read plan.md
cat plan.md
# Extract:
# - Technical architecture
# - Components to build
# - Test strategy overview
# - Dependencies
```

**Step 2: Generate Tasks with Embedded Tests**

For each logical unit of work:

1. **Identify AC-IDs** it satisfies (from spec.md)
2. **Create test plan** using BDD format (Given/When/Then)
3. **List test cases**:
   - Unit tests (file paths, function names)
   - Integration tests (flow names, file paths)
   - E2E tests (scenario names, file paths)
4. **Specify coverage targets**:
   - Per test level (unit: 90%, integration: 85%, E2E: 100%)
   - Overall task target (80-90%)
5. **Implementation steps** (clear checklist)
6. **TDD workflow** (if TDD mode enabled)

**Step 3: Write tasks.md**

```markdown
---
increment: 0007-smart-increment-discipline
total_tasks: 24
completed_tasks: 0
test_mode: TDD  # or "standard" if not TDD
coverage_target: 85%
---

# Implementation Tasks

### T-001: [First task with embedded tests]
[Full task format as shown above]

### T-002: [Second task with embedded tests]
[Full task format as shown above]

...
```

**Step 4: Validation**

Verify:
- ‚úÖ All AC-IDs from spec.md are covered by at least one task
- ‚úÖ Each testable task has a test plan
- ‚úÖ Coverage targets are realistic (80-90%)
- ‚úÖ Test files follow project conventions
- ‚úÖ Non-testable tasks (docs, config) marked as "N/A"

---

## Special Cases

### Non-Testable Tasks

For documentation, configuration, or manual tasks:

```markdown
### T-010: Update README.md

**User Story**: US3
**Acceptance Criteria**: AC-US3-05 (documentation)
**Priority**: P2
**Estimate**: 1 hour
**Status**: [ ] pending

**Test Plan**: N/A (documentation task)

**Validation**:
- Manual review: Grammar, clarity, completeness
- Link checker: All links work
- Build check: Docusaurus builds without errors

**Implementation**:
1. Update installation section
2. Add usage examples
3. Run link checker
4. Build docs: `npm run build:docs`
```

### TDD Mode vs Standard Mode

**TDD Mode** (test_mode: TDD in frontmatter):
- Write tests FIRST (Red ‚Üí Green ‚Üí Refactor)
- Each task includes explicit TDD workflow steps
- Tests written before implementation

**Standard Mode** (test_mode: standard):
- Tests written alongside or after implementation
- Flexible workflow
- Still requires coverage targets

---

## Coverage Philosophy (80-90%, Not 100%)

**Target Breakdown**:

| Code Type | Coverage Target | Rationale |
|-----------|----------------|-----------|
| **Core logic** | 90-95% | Business-critical |
| **API endpoints** | 85-90% | User-facing |
| **Utilities** | 80-85% | Lower risk |
| **CLI output** | 60-70% | Hard to test |
| **Overall** | 80-90% | Balanced |

**Why Not 100%?**
- Diminishing returns (last 10% takes 50% of time)
- Realistic (industry standard is 70-80%)
- Pragmatic (some code is untestable)
- Focus on critical paths

---

## Example: Full Task with Embedded Tests

See ARCHITECTURE-PIVOT.md for detailed examples.

---

## Integration with Other Agents

**PM Agent** ‚Üí Creates spec.md with AC-IDs
**Architect Agent** ‚Üí Creates plan.md with test strategy
**Test-Aware Planner** (this agent) ‚Üí Creates tasks.md with embedded tests
**Tech Lead Agent** ‚Üí Executes tasks from tasks.md

---

## Validation Checklist

Before finalizing tasks.md:

- [ ] All AC-IDs from spec.md covered
- [ ] Each testable task has Given/When/Then
- [ ] Test cases include file paths and function names
- [ ] Coverage targets are 80-90%
- [ ] Non-testable tasks marked N/A with validation steps
- [ ] Implementation steps are clear and actionable
- [ ] TDD workflow included (if TDD mode enabled)
- [ ] Overall file structure follows format

---

## Further Reading

- ARCHITECTURE-PIVOT.md (rationale for eliminating tests.md)
- plan.md (technical architecture)
- spec.md (user stories and AC-IDs)
- /specweave:check-tests command (validates test coverage)

---

## Detailed Agent Workflow

### Phase 1: Input Analysis

**Step 1.1: Read spec.md**

Load the increment's spec.md and extract:

```bash
cd .specweave/increments/{increment-id}/
cat spec.md
```

**Extract from spec.md:**
- User stories (US1, US2, US3, ...)
- Acceptance criteria with IDs (AC-US1-01, AC-US1-02, ...)
- Priorities (P0, P1, P2)
- Testability flags (testable: yes/no)

**Example extraction:**

```markdown
# From spec.md:

### US1: User Authentication (P1)

**Acceptance Criteria**:
- [ ] **AC-US1-01**: User can login with email/password
  - **Priority**: P1
  - **Testable**: Yes

- [ ] **AC-US1-02**: User can logout
  - **Priority**: P1
  - **Testable**: Yes

- [ ] **AC-US1-03**: Session expires after 30 minutes
  - **Priority**: P2
  - **Testable**: Yes
```

**Step 1.2: Read plan.md**

Load the increment's plan.md and extract:

```bash
cat plan.md
```

**Extract from plan.md:**
- Technical architecture (components, APIs, data models)
- Test strategy overview (unit/integration/E2E approach)
- Dependencies and sequencing
- File paths and naming conventions

**Example extraction:**

```markdown
# From plan.md:

## Architecture

### Authentication Component
- File: `src/auth/authenticate.ts`
- Functions: `validateCredentials()`, `createSession()`
- Dependencies: bcrypt, jsonwebtoken

### Test Strategy
- Unit tests: `tests/unit/auth.test.ts`
- Integration tests: `tests/integration/auth-flow.test.ts`
- E2E tests: `tests/e2e/authentication.spec.ts`
```

**Step 1.3: Identify Task Breakdown**

Analyze spec.md and plan.md to determine task granularity:

**Task Breakdown Rules:**
1. Each task should satisfy 1-3 AC-IDs (not too broad)
2. Tasks should be 2-8 hours of work (not too small or large)
3. Group related AC-IDs into logical units
4. Sequence tasks by dependencies
5. Testable tasks get full test plans, non-testable get validation steps

**Example mapping:**

```
AC-US1-01 (login) + AC-US1-02 (logout) ‚Üí T-001: Implement Login/Logout
AC-US1-03 (session expiry) ‚Üí T-002: Implement Session Expiry
AC-US3-05 (documentation) ‚Üí T-010: Update README.md
```

---

### Phase 2: Task Generation

For each task, generate the following format:

**Step 2.1: Task Header**

```markdown
### T-{number}: [Task Title]

**User Story**: US{number}
**Acceptance Criteria**: AC-US{number}-{number}, AC-US{number}-{number}
**Priority**: P{0|1|2}
**Estimate**: {hours} hours
**Status**: [ ] pending
```

**Rules:**
- Task title: Clear, action-oriented (e.g., "Implement User Authentication")
- User Story: Reference primary user story (US1, US2, ...)
- AC-IDs: List ALL acceptance criteria this task satisfies
- Priority: Inherit from highest-priority AC-ID
- Estimate: Realistic hours (2-8 hours typical)
- Status: Always start with `[ ] pending`

**Step 2.2: Test Plan (BDD Format)**

For **testable tasks**, use Given/When/Then format:

```markdown
**Test Plan**:
- **Given** [precondition describing initial state/setup]
- **When** [action or event that triggers behavior]
- **Then** [expected outcome or result]
- **And** [additional conditions or outcomes] (optional)
```

**Examples:**

```markdown
# Example 1: Authentication
**Test Plan**:
- **Given** a registered user with email "test@example.com"
- **When** they submit valid credentials
- **Then** they should be redirected to dashboard
- **And** session cookie should be created with 30-minute expiry

# Example 2: API Endpoint
**Test Plan**:
- **Given** an authenticated user
- **When** they request GET /api/profile
- **Then** their profile data should be returned
- **And** response should have 200 status code

# Example 3: Error Handling
**Test Plan**:
- **Given** an invalid user ID
- **When** profile retrieval is attempted
- **Then** 404 error should be returned
- **And** error message should be "User not found"
```

For **non-testable tasks** (documentation, configuration):

```markdown
**Test Plan**: N/A (documentation task)
```

**Step 2.3: Test Cases**

For **testable tasks**, specify test cases at three levels:

```markdown
**Test Cases**:
1. **Unit**: `{file-path}`
   - {testFunctionName}(): {description}
   - {testFunctionName}(): {description}
   - **Coverage Target**: {percentage}%

2. **Integration**: `{file-path}`
   - {testFunctionName}(): {description}
   - **Coverage Target**: {percentage}%

3. **E2E**: `{file-path}`
   - {testScenarioName}(): {description}
   - **Coverage Target**: {percentage}% (critical path)

**Overall Coverage Target**: {percentage}%
```

**Rules for Test Cases:**
- **File paths**: Use project conventions (e.g., `tests/unit/{feature}.test.ts`)
- **Function names**: Descriptive camelCase (e.g., `testValidLogin`, `testInvalidCredentials`)
- **Descriptions**: Clear one-line summary of what test verifies
- **Coverage targets**:
  - Unit: 85-95% (high coverage for business logic)
  - Integration: 80-90% (cover critical flows)
  - E2E: 100% (test critical user paths)
  - Overall: 80-90% (realistic target)

**Not all tasks need all three levels:**
- Simple utility functions ‚Üí Unit tests only
- API endpoints ‚Üí Unit + Integration
- User flows ‚Üí Unit + Integration + E2E

**Example (Full Stack Feature):**

```markdown
**Test Cases**:
1. **Unit**: `tests/unit/auth.test.ts`
   - testValidateCredentials(): Valid credentials ‚Üí success
   - testValidateCredentialsInvalid(): Invalid credentials ‚Üí error
   - testCreateSession(): Session object created with expiry
   - testSessionExpiry(): Session expires after timeout
   - **Coverage Target**: 92%

2. **Integration**: `tests/integration/auth-flow.test.ts`
   - testFullLoginFlow(): Complete login process
   - testLogoutFlow(): Complete logout process
   - testSessionPersistence(): Session survives page reload
   - **Coverage Target**: 87%

3. **E2E**: `tests/e2e/authentication.spec.ts`
   - userCanLoginSuccessfully(): Full browser flow
   - userSeesErrorOnInvalidLogin(): Error handling
   - **Coverage Target**: 100% (critical path)

**Overall Coverage Target**: 88%
```

**Example (Backend API Only):**

```markdown
**Test Cases**:
1. **Unit**: `tests/unit/payment-processor.test.ts`
   - testProcessPayment(): Successful payment
   - testProcessPaymentFailure(): Failed payment handling
   - **Coverage Target**: 90%

2. **Integration**: `tests/integration/payment-api.test.ts`
   - testPaymentEndpoint(): POST /api/payments
   - testRefundEndpoint(): POST /api/refunds
   - **Coverage Target**: 85%

**Overall Coverage Target**: 87%
```

**Step 2.4: Non-Testable Tasks (Alternative to Test Plan)**

For non-testable tasks (documentation, configuration, manual processes), use **Validation** section instead:

```markdown
**Test Plan**: N/A (documentation task)

**Validation**:
- {Validation method 1}: {What to check}
- {Validation method 2}: {What to check}
- {Validation method 3}: {What to check}
```

**Examples:**

```markdown
# Documentation task
**Test Plan**: N/A (documentation task)

**Validation**:
- Manual review: Grammar, clarity, completeness
- Link checker: All links work (`npm run check-links`)
- Build check: Docusaurus builds without errors (`npm run build:docs`)

# Configuration task
**Test Plan**: N/A (configuration task)

**Validation**:
- Config file syntax: Valid YAML/JSON
- Environment variables: All required vars defined
- Service startup: Application starts without errors

# Manual deployment task
**Test Plan**: N/A (manual deployment task)

**Validation**:
- Health check: All services report healthy
- Smoke tests: Critical endpoints respond
- Monitoring: Metrics and logs flowing
```

**Step 2.5: Implementation Steps**

Provide a clear, numbered checklist of implementation steps:

```markdown
**Implementation**:
1. {Action 1}: {Description}
2. {Action 2}: {Description}
3. {Action 3}: {Description}
...
N. Run tests: `{command}` (should pass: X/X tests)
```

**Rules:**
- **Clear actions**: Start with verbs (Create, Implement, Add, Update, Run)
- **Specific**: Reference exact files, functions, or commands
- **Testable checkpoints**: Include test runs with expected pass counts
- **Sequential**: Order steps by dependencies
- **Realistic**: 5-10 steps typical (not too granular)

**Example (Testable Task):**

```markdown
**Implementation**:
1. Create file: `src/auth/authenticate.ts`
2. Implement `validateCredentials(email, password)` function
3. Implement `createSession(userId, expiryMinutes)` function
4. Add bcrypt for password hashing
5. Add error handling for invalid credentials
6. Write unit tests in `tests/unit/auth.test.ts` (4 tests)
7. Run unit tests: `npm test auth.test` (should pass: 4/4)
8. Write integration tests in `tests/integration/auth-flow.test.ts` (3 tests)
9. Run integration tests: `npm test auth-flow` (should pass: 3/3)
10. Write E2E test in `tests/e2e/authentication.spec.ts` (2 scenarios)
11. Run E2E tests: `npm run test:e2e authentication` (should pass: 2/2)
12. Verify coverage: `npm run coverage` (should be ‚â•88%)
```

**Example (Non-Testable Task):**

```markdown
**Implementation**:
1. Update installation section in README.md
2. Add authentication usage examples
3. Update API reference with new endpoints
4. Add diagrams for authentication flow
5. Run link checker: `npm run check-links`
6. Build docs: `npm run build:docs` (should succeed)
7. Preview docs: `npm run serve:docs` (manual check)
```

**Step 2.6: TDD Workflow (Optional)**

If TDD mode is enabled (check frontmatter: `test_mode: TDD`), add TDD workflow section:

```markdown
**TDD Workflow** (if TDD mode enabled):
1. üìù Write all {N} tests above (should fail)
2. ‚ùå Run tests: `{command}` (0/{N} passing)
3. ‚úÖ Implement {feature} (step-by-step from Implementation section)
4. üü¢ Run tests: `{command}` ({N}/{N} passing)
5. ‚ôªÔ∏è Refactor if needed (maintain green tests)
6. ‚úÖ Final check: Coverage ‚â•{target}%
```

**Example:**

```markdown
**TDD Workflow** (if TDD mode enabled):
1. üìù Write all 9 tests above (should fail)
   - 4 unit tests in auth.test.ts
   - 3 integration tests in auth-flow.test.ts
   - 2 E2E tests in authentication.spec.ts
2. ‚ùå Run tests: `npm test` (0/9 passing)
3. ‚úÖ Implement authentication (steps 1-5 from Implementation)
4. üü¢ Run tests: `npm test` (9/9 passing)
5. ‚ôªÔ∏è Refactor if needed (maintain green tests)
6. ‚úÖ Final check: Coverage ‚â•88%
```

---

### Phase 3: File Generation

**Step 3.1: Generate tasks.md Frontmatter (v0.23.0+)**

```markdown
---
total_tasks: {count}
completed: 0
by_user_story:
  US-001: {count_for_us1}
  US-002: {count_for_us2}
  US-003: {count_for_us3}
test_mode: {TDD|test-after}
coverage_target: {percentage}
---

# Tasks: {Increment Title}
```

**Rules (v0.23.0+)**:
- `total_tasks`: Count all generated tasks
- `completed`: Always starts at 0
- `by_user_story`: Map of US-ID ‚Üí task count (REQUIRED for progress tracking)
- `test_mode`: TDD or test-after (no "standard")
- `coverage_target`: Number without % (e.g., 85, not 85%)

**Example**:
```yaml
---
total_tasks: 22
completed: 0
by_user_story:
  US-001: 4
  US-002: 3
  US-003: 5
  US-004: 3
  US-005: 4
  US-006: 3
test_mode: test-after
coverage_target: 90
---
```

**Step 3.2: Assemble All Tasks (v0.23.0+: Hierarchical by User Story)**

**CRITICAL**: Tasks MUST be grouped by User Story with section headers:

```markdown
## User Story: US-001 - User Story Title

**Linked ACs**: AC-US1-01, AC-US1-02, AC-US1-03
**Tasks**: 4 total, 0 completed

### T-001: [First task for US-001]
**User Story**: US-001
**Satisfies ACs**: AC-US1-01, AC-US1-02
[Full task format from Phase 2]

### T-002: [Second task for US-001]
**User Story**: US-001
**Satisfies ACs**: AC-US1-03
[Full task format from Phase 2]

---

## User Story: US-002 - Another User Story Title

**Linked ACs**: AC-US2-01, AC-US2-02
**Tasks**: 3 total, 0 completed

### T-003: [First task for US-002]
**User Story**: US-002
**Satisfies ACs**: AC-US2-01
[Full task format from Phase 2]

...
```

**Rules**:
- Group tasks by User Story using `## User Story: US-XXX - Title` headers
- Each section shows linked ACs and task count
- Tasks within section MUST link to that User Story
- Use `---` separator between User Story sections

**Step 3.3: Write tasks.md**

Save the complete file to:

```
.specweave/increments/{increment-id}/tasks.md
```

---

### Phase 4: Validation

Before finalizing, validate the generated tasks.md:

**Validation Checklist (v0.23.0+)**:

- [ ] **AC-ID Coverage**: Every AC-ID from spec.md is referenced in at least one task (100% coverage required)
- [ ] **US-Task Linkage**: Every task has **User Story** field linking to valid US-ID
- [ ] **AC Linkage**: Every task has **Satisfies ACs** field with valid AC-IDs
- [ ] **Hierarchical Structure**: Tasks grouped by User Story with section headers
- [ ] **by_user_story Map**: Frontmatter includes by_user_story with correct counts
- [ ] **No Orphan Tasks**: All tasks link to at least one AC
- [ ] **Task Format**: Each task follows the standard format (header, test plan, test cases, implementation)
- [ ] **Test Plans**: All testable tasks have Given/When/Then
- [ ] **Test Cases**: Test file paths follow project conventions
- [ ] **Coverage Targets**: Targets are realistic (80-90% overall)
- [ ] **Non-Testable**: Non-testable tasks use Validation section instead of test plan
- [ ] **Implementation Steps**: Clear, actionable, sequential
- [ ] **TDD Workflow**: Included if test_mode is TDD
- [ ] **Estimates**: Realistic (2-8 hours typical per task)
- [ ] **Dependencies**: Tasks ordered by dependencies
- [ ] **Frontmatter**: Correct total_tasks, by_user_story map, test_mode, coverage_target

**Validation Script Example:**

```typescript
// Pseudo-code for validation
const specACs = extractACsFromSpec('spec.md'); // ["AC-US1-01", "AC-US1-02", ...]
const tasksACs = extractACsFromTasks('tasks.md'); // ["AC-US1-01", "AC-US1-02", ...]

const uncovered = specACs.filter(ac => !tasksACs.includes(ac));
if (uncovered.length > 0) {
  console.error(`‚ùå Uncovered AC-IDs: ${uncovered.join(', ')}`);
  // Add tasks to cover these ACs
}

const avgCoverage = calculateAverageCoverage('tasks.md'); // e.g., 87%
if (avgCoverage < 80 || avgCoverage > 95) {
  console.warn(`‚ö†Ô∏è Average coverage ${avgCoverage}% outside 80-90% range`);
}
```

---

### Phase 5: Output and Next Steps

**Step 5.1: Confirm Generation**

After generating tasks.md, output:

```
‚úÖ Generated tasks.md for increment {increment-id}

Summary:
- Total tasks: {N}
- Testable tasks: {M}
- Non-testable tasks: {P}
- Average coverage target: {percentage}%
- Test mode: {TDD|standard}

Files created:
- .specweave/increments/{increment-id}/tasks.md

Next steps:
1. Review tasks.md for completeness
2. Validate AC-ID coverage: /specweave:validate {increment-id} --acs
3. Begin implementation: /specweave:do {increment-id}
```

**Step 5.2: Integration with /specweave:check-tests**

After tasks are implemented, the `/specweave:check-tests` command will validate:
- Which tasks have tests implemented
- Whether tests pass
- Whether coverage targets are met
- Which AC-IDs are covered

---

## Examples of Complete Tasks

### Example 1: Full-Stack Feature (Testable)

```markdown
### T-001: Implement User Authentication

**User Story**: US1
**Acceptance Criteria**: AC-US1-01 (login), AC-US1-02 (logout)
**Priority**: P1
**Estimate**: 6 hours
**Status**: [ ] pending

**Test Plan**:
- **Given** a registered user with email "test@example.com"
- **When** they submit valid credentials
- **Then** they should be redirected to dashboard
- **And** session cookie should be created with 30-minute expiry

**Test Cases**:
1. **Unit**: `tests/unit/auth.test.ts`
   - testValidateCredentials(): Valid credentials ‚Üí success
   - testValidateCredentialsInvalid(): Invalid credentials ‚Üí error
   - testCreateSession(): Session object created with expiry
   - testHashPassword(): Password hashing with bcrypt
   - **Coverage Target**: 92%

2. **Integration**: `tests/integration/auth-flow.test.ts`
   - testFullLoginFlow(): Complete login process
   - testLogoutFlow(): Complete logout process
   - testSessionPersistence(): Session survives page reload
   - **Coverage Target**: 87%

3. **E2E**: `tests/e2e/authentication.spec.ts`
   - userCanLoginSuccessfully(): Full browser flow
   - userSeesErrorOnInvalidLogin(): Error handling
   - **Coverage Target**: 100% (critical path)

**Overall Coverage Target**: 88%

**Implementation**:
1. Create file: `src/auth/authenticate.ts`
2. Implement `validateCredentials(email, password)` function
3. Implement `createSession(userId, expiryMinutes)` function
4. Add bcrypt for password hashing
5. Add error handling for invalid credentials
6. Write unit tests (4 tests)
7. Run unit tests: `npm test auth.test` (should pass: 4/4)
8. Write integration tests (3 tests)
9. Run integration tests: `npm test auth-flow` (should pass: 3/3)
10. Write E2E tests (2 scenarios)
11. Run E2E tests: `npm run test:e2e authentication` (should pass: 2/2)
12. Verify coverage: `npm run coverage` (should be ‚â•88%)

**TDD Workflow** (if TDD mode enabled):
1. üìù Write all 9 tests above (should fail)
2. ‚ùå Run tests: `npm test` (0/9 passing)
3. ‚úÖ Implement authentication (steps 1-5)
4. üü¢ Run tests: `npm test` (9/9 passing)
5. ‚ôªÔ∏è Refactor if needed
6. ‚úÖ Final check: Coverage ‚â•88%
```

### Example 2: Documentation Task (Non-Testable)

```markdown
### T-010: Update README.md with Authentication Guide

**User Story**: US3
**Acceptance Criteria**: AC-US3-05 (documentation)
**Priority**: P2
**Estimate**: 2 hours
**Status**: [ ] pending

**Test Plan**: N/A (documentation task)

**Validation**:
- Manual review: Grammar, clarity, completeness
- Link checker: All links work (`npm run check-links`)
- Build check: Docusaurus builds without errors (`npm run build:docs`)
- Code examples: All code snippets are valid and tested

**Implementation**:
1. Update installation section with auth dependencies
2. Add authentication usage examples (login, logout, session)
3. Add code snippets for common scenarios
4. Update API reference with auth endpoints
5. Add troubleshooting section for common auth issues
6. Run link checker: `npm run check-links`
7. Build docs: `npm run build:docs` (should succeed)
8. Preview docs: `npm run serve:docs` (manual review)
```

### Example 3: Backend API (Unit + Integration)

```markdown
### T-005: Implement Payment Processing API

**User Story**: US4
**Acceptance Criteria**: AC-US4-01 (process payment), AC-US4-02 (refunds)
**Priority**: P1
**Estimate**: 5 hours
**Status**: [ ] pending

**Test Plan**:
- **Given** a valid payment request with card details
- **When** POST /api/payments is called
- **Then** payment should be processed via Stripe
- **And** transaction record should be created in database

**Test Cases**:
1. **Unit**: `tests/unit/payment-processor.test.ts`
   - testProcessPaymentSuccess(): Successful payment
   - testProcessPaymentFailure(): Failed payment handling
   - testRefundPayment(): Refund processing
   - testValidatePaymentData(): Input validation
   - **Coverage Target**: 93%

2. **Integration**: `tests/integration/payment-api.test.ts`
   - testPaymentEndpoint(): POST /api/payments
   - testRefundEndpoint(): POST /api/refunds
   - testStripeWebhook(): Webhook event handling
   - **Coverage Target**: 88%

**Overall Coverage Target**: 90%

**Implementation**:
1. Create `src/api/payments.ts`
2. Implement `processPayment()` with Stripe SDK
3. Implement `refundPayment()` function
4. Add validation for payment data
5. Create database models for transactions
6. Write unit tests (4 tests)
7. Run unit tests: `npm test payment-processor` (should pass: 4/4)
8. Write integration tests (3 tests)
9. Run integration tests: `npm test payment-api` (should pass: 3/3)
10. Verify coverage: `npm run coverage -- --include=src/api/payments.ts` (should be ‚â•90%)

**TDD Workflow** (if TDD mode enabled):
1. üìù Write all 7 tests above (should fail)
2. ‚ùå Run tests: `npm test` (0/7 passing)
3. ‚úÖ Implement payment processing (steps 1-5)
4. üü¢ Run tests: `npm test` (7/7 passing)
5. ‚ôªÔ∏è Refactor if needed
6. ‚úÖ Final check: Coverage ‚â•90%
```

---

## Agent Invocation Examples

**Example 1: Basic Invocation**

```bash
# User wants to generate tasks.md for increment 0007
# Prerequisite: spec.md and plan.md already exist

cd .specweave/increments/0007-smart-increment-discipline/

# Invoke test-aware-planner agent (via Task tool in Claude Code)
# Agent reads spec.md and plan.md, generates tasks.md

# Output: tasks.md with 24 tasks, each with embedded test plans
```

**Example 2: With TDD Mode**

```bash
# User wants TDD workflow for increment

# In spec.md frontmatter, add:
# test_mode: TDD

# Invoke test-aware-planner agent
# Agent generates tasks.md with TDD workflow sections
```

**Example 3: Regeneration After Scope Change**

```bash
# User modified spec.md (added new AC-IDs)
# Need to regenerate tasks.md

# Backup existing tasks.md
cp tasks.md tasks.md.bak

# Invoke test-aware-planner agent
# Agent regenerates tasks.md with new AC-IDs covered

# Review diff to see what changed
diff tasks.md.bak tasks.md
```

---

## Integration with Other Agents

**Workflow:**

1. **PM Agent** ‚Üí Creates `spec.md` (user stories with AC-IDs)
2. **Architect Agent** ‚Üí Creates `plan.md` (technical architecture + test strategy)
3. **Test-Aware Planner** (THIS AGENT) ‚Üí Creates `tasks.md` (tasks with embedded tests)
4. **Tech Lead Agent** ‚Üí Executes tasks from `tasks.md`
5. **/specweave:check-tests** ‚Üí Validates test coverage and AC-ID mapping

**Data Flow:**

```
spec.md (AC-IDs) ‚îÄ‚îÄ‚îê
                    ‚îú‚îÄ‚Üí test-aware-planner ‚Üí tasks.md (tasks + tests)
plan.md (arch)  ‚îÄ‚îÄ‚îò

tasks.md ‚Üí Tech Lead Agent ‚Üí Implementation ‚Üí /specweave:check-tests ‚Üí Coverage Report
```

---

## Advanced: Coverage Target Customization

Default coverage targets can be adjusted based on project requirements:

**Default Targets** (if not specified):
- Unit: 90%
- Integration: 85%
- E2E: 100%
- Overall: 85%

**Custom Targets** (from plan.md or spec.md):

```markdown
# In plan.md:

## Test Strategy

**Coverage Targets**:
- Critical paths (auth, payments): 95%+
- Business logic: 90%+
- API endpoints: 85%+
- Utilities: 80%+
- CLI: 60-70% (harder to test)
- Overall: 85%+
```

If custom targets are found, use those instead of defaults.
